# -*- coding: utf-8 -*-
"""diabetes_picklefile.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkSecK0blD6q6rSeK8in3t96BT2eVap6
"""

import numpy as np
import pandas as pd
df=pd.read_csv('/content/diabetes.csv')
df
# typing interface is called cell

df.head()
df['Outcome'].value_counts()

df.tail()

df.dtypes
# all dtypes should be in numerical forms ow convert to numerical form thet process is called encoding

df.ndim

df.isna().sum()

df.columns

x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']].values
x

x=df.iloc[:,:-1].values
x

# i/p always 1D data and o/p always 1D
# i/p and o/p should be in arrays
y=df.iloc[:,-1].values
y

x.ndim
y.ndim

# divide in to training and testing data
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=1)
x_train

x_test

y_test

y_train

# Normalisation:Normalization in machine learning is a technique used to adjust the scale of features so that they contribute equally to the model's performance.
# It ensures that no single feature dominates others due to its larger range of values,
# improving the stability and performance of various algorithms, especially those that rely on distance or gradient-based optimization.
# 1.Standard Scalar or (Z-score Normalization)

# Xstd=(X−μ)/σ
# Where:

#     X_std: The normalized value
#     X: The original value
#     μ: The mean of the feature
#     σ: The standard deviation of the feature

# This method centers the data around zero mean and unit variance.
# It makes the features have a similar range of values and is less sensitive to outliers.

# 2.min - max scalar:

# Equation: X_scaled = (X - X_min) / (X_max - X_min)
# Where:

#     X_scaled: The normalized value
#     X: The original value
#     X_min: The minimum value of the feature
#     X_max: The maximum value of the feature

# This method scales the data to a specific range, typically between 0 and 1. It preserves
# the relationships between the original data values but is more sensitive to outliers compared to StandardScaler.

# from sklearn.preprocessing import MinMaxScaler

# # Create a MinMaxScaler object
# scaler = MinMaxScaler()

# # Fit the scaler to your data
# scaler.fit(your_data)

# # Transform your data
# scaled_data = scaler.transform(your_data)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(x_train) #standandard scalar is calculated with training values
x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

x_train

x_test

from sklearn.neighbors import KNeighborsClassifier
model=KNeighborsClassifier(n_neighbors=7)
model.fit(x_train,y_train)
y_predict=model.predict(x_test)
y_predict

y_test

# insert normalised values while giving user i/p values
print(model.predict(scaler.transform([[6,148,72,35,0,33.6,0.627,50]])))

"""# Performance Evaluation method of classification

# 1.Accuracy score
# 2.Recall
# 3.Precision
# 4.F1_Score

# all evaluation methods are based on Confusion matrix

# A confusion matrix is a table used to evaluate the performance of a classification model,
# like the KNeighborsClassifier you used in your code for diabetes prediction.
# It's a way to visualize how well your model is doing by comparing its predictions to the actual values (y_test in your case).



**All these performance methods work on the basis of a matrix called Confusion Matrix.



There are 4 technical terms inside a Confusion Matrix:

	TP : True Positive
	TN : True Negative
	FP : False Positive
	FN : False Negative
**

# Here's how it works:

#     Structure: The confusion matrix is typically a 2x2 table for binary classification (like your diabetes prediction where the outcome is 0 or 1). It has four quadrants:
#         **True Positive (TP)**: The model correctly predicted a positive outcome (patient has diabetes) when it was actually positive.
#         **True Negative (TN)**: The model correctly predicted a negative outcome (patient does not have diabetes) when it was actually negative.
#         **False Positive (FP)**: The model incorrectly predicted a positive outcome (Type I error).
#         False Negative (FN): The model incorrectly predicted a negative outcome (Type II error).

# 2*2 matrix:based on output(1/0) and prediction(1/0)
3*3 matrix:based on output(0/1/2) and prediction(0/1/2)

# quadrant

  #  tp   fp
  #  fn   tn

**Accuracy:** This is the most intuitive metric, representing the overall correctness of the model's predictions. It's calculated as:
Accuracy = (TP + TN) / (TP + TN + FP + FN)
"""

# performance evaluation
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_predict)
cm

from sklearn.metrics import accuracy_score
score=accuracy_score(y_test,y_predict)
score

"""Reasons for Accuracy Fluctuations:

   **Randomness in Train-Test Split: **
        In your code, you use train_test_split to divide your data into training and testing sets. By default, this function introduces randomness in the split, meaning that different data points will be assigned to the training and testing sets each time you run the code.
        Since the model is trained on a different subset of data each time, its performance on the test set can vary, leading to fluctuations in accuracy.

**Solution:**
    To ensure consistent results, you can set a random seed using the random_state parameter in train_test_split:
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)  # Replace 42 with any integer like 0,1.

*   This will fix the random split, ensuring that the same data points are used for training and testing every time you run the code, leading to more stable accuracy.


```




"""

from sklearn.metrics import classification_report
cr=classification_report(y_test,y_predict)
print(cr)

import pickle

with open('model_pickle.pkl','wb') as file:
  # wb=to write
  pickle.dump(model,file)